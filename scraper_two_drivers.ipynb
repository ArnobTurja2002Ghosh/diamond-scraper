{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to scrape diamonds data. This could take a while...\n",
      "CSV path: /Users/miguel/Git Repos/DiamondScraper/data/2020-11-29 04-53 PM.csv\n",
      "Finished in 2.7 minutes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from time import perf_counter, sleep\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "from gazpacho import Soup\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "\n",
    "# set timestamp\n",
    "timestamp = f\"{pd.Timestamp('today'):%Y-%m-%d %I-%M %p}\"\n",
    "\n",
    "# create project directories\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('screenshots', exist_ok=True)\n",
    "\n",
    "# define CSV path\n",
    "cwd = os.getcwd()\n",
    "csv_path = ''.join((cwd, '/data/', timestamp, '.csv'))\n",
    "\n",
    "\n",
    "def create_driver():\n",
    "    # create headless Firefox WebDriver instance\n",
    "    # options = Options()\n",
    "    # options.headless = True\n",
    "    driver = Firefox(executable_path='/usr/local/bin/geckodriver') # options=options)\n",
    "    driver_id = driver.session_id\n",
    "    return driver, driver_id\n",
    "\n",
    "\n",
    "def take_screenshot():\n",
    "    \"\"\"Saves a screenshot of the current window in the 'screenshots' directory.\"\"\"\n",
    "    path = ''.join((\n",
    "        './screenshots/', 'screenshot ', timestamp, '.png')\n",
    "    )\n",
    "    driver.save_screenshot(path)\n",
    "\n",
    "\n",
    "def make_soup(driver):\n",
    "    \"\"\"Makes soup on raw html to enable parsing.\"\"\"\n",
    "    html = driver.page_source\n",
    "    return Soup(html)\n",
    "\n",
    "\n",
    "def load_url(driver, diamond_type):\n",
    "    \"\"\"Navigates to Brilliant Earth's diamonds search page.\"\"\"\n",
    "    base = 'https://www.brilliantearth.com/'\n",
    "    nat_url = base + \"/loose-diamonds/search/\"\n",
    "    lab_url = base + \"lab-diamonds-search/\"\n",
    "    if diamond_type == 'lab':\n",
    "        driver.get(lab_url)\n",
    "    else:\n",
    "        driver.get(nat_url)\n",
    "\n",
    "\n",
    "def close_marketing_box(driver):\n",
    "    \"\"\"Closes the marketing box when first loading the page.\"\"\"\n",
    "    # wait a maximum of 60 seconds to close the box\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            ec.presence_of_element_located((By.CLASS_NAME, 'sailthru-overlay-close'))\n",
    "        ).click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "def get_shapes(driver):\n",
    "    \"\"\"Returns a list of available shapes.\"\"\"\n",
    "    soup = make_soup(driver)\n",
    "    a = soup.find('div', {'class': 'ir246-product-shape-wrap'})\n",
    "    b = a.find('a')\n",
    "    return [shape.text.lower() for shape in b]\n",
    "\n",
    "\n",
    "def select_shapes(driver, ix: int):\n",
    "    \"\"\"Selects diamond shapes on the first pass.\"\"\"\n",
    "    if ix == 0:\n",
    "        shapes = get_shapes(driver)\n",
    "        for shape in shapes:\n",
    "            shape_element = '-'.join((shape, 'details'))\n",
    "            driver.find_element_by_class_name(shape_element).click()\n",
    "        sleep(3)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "def perform_actions(driver, element: str, box_input: str):\n",
    "    \"\"\"Takes actions on input box elements.\"\"\"\n",
    "    # find element\n",
    "    e = driver.find_element_by_id(element)\n",
    "\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(e)\n",
    "    actions.click()\n",
    "    actions.send_keys(Keys.BACKSPACE * 10)\n",
    "    actions.send_keys(box_input + Keys.RETURN)\n",
    "    actions.perform()\n",
    "    sleep(1)\n",
    "\n",
    "    # click header\n",
    "    header = driver.find_element_by_tag_name('h1')\n",
    "    header.click()\n",
    "\n",
    "\n",
    "def set_max_price(driver):\n",
    "    \"\"\"Re-adjusts the max price box in the results table.\"\"\"\n",
    "    perform_actions(driver, 'max_price_display', '10000000')\n",
    "\n",
    "\n",
    "def set_max_carat(driver):\n",
    "    \"\"\"Re-adjusts the carat box in the results table.\"\"\"\n",
    "    perform_actions(driver, 'max_carat_display', '50')\n",
    "\n",
    "\n",
    "def table_scroll(driver):\n",
    "    \"\"\"Scrolls down the diamond data table.\n",
    "    The table loads a maximum of 200 items per position.\n",
    "    \"\"\"\n",
    "    base_script = \"document.querySelector('#diamond_search_wrapper').scrollTop=\"\n",
    "    positions = ['6766', '13566', '20366', '27166', '33966']\n",
    "    prev_n_items = 0\n",
    "\n",
    "    for p in positions:\n",
    "        # make soup & find items\n",
    "        soup = make_soup(driver)\n",
    "        items = soup.find('div', {'class': 'inner item'})\n",
    "\n",
    "        # check if 'items' is a list\n",
    "        if isinstance(items, list):\n",
    "            n_items = len(items)\n",
    "            diff = n_items - prev_n_items\n",
    "\n",
    "            # if 200 items loaded, track 'n_items' & scroll down to load more\n",
    "            if diff == 200:\n",
    "                prev_n_items = n_items\n",
    "                scroll_by = ''.join((base_script, p))\n",
    "                driver.execute_script(scroll_by)\n",
    "                sleep(3)\n",
    "            else:\n",
    "                # if there are fewer than 200 items, all items have been loaded\n",
    "                break\n",
    "        # if 'items' is not a list (a single item), break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "\n",
    "def create_dataframe(driver):\n",
    "    \"\"\"Returns pandas DataFrame from diamonds HTML page.\"\"\"\n",
    "    html = driver.page_source\n",
    "    dfs = pd.read_html(html)\n",
    "\n",
    "    # return the second table which contains target data\n",
    "    return dfs[1]\n",
    "\n",
    "\n",
    "def clean_table_df(df):\n",
    "    \"\"\"\"Returns clean diamonds pandas DataFrame.\"\"\"\n",
    "    assert df.shape[1] == 10, \"Number of columns needs to be 10.\"\n",
    "\n",
    "    # rename columns\n",
    "    df.columns = ['0', 'shape', 'price', 'carat', 'cut', 'color', 'clarity',\n",
    "                  'report', 'compare', 'checkbox']\n",
    "\n",
    "    # drop blank rows & useless columns\n",
    "    df = (df.dropna(axis=0, how='all', thresh=3)\n",
    "          .drop(columns=['0', 'compare', 'checkbox']))\n",
    "\n",
    "    # remove '$' and commas, and convert float to int\n",
    "    df['price'] = df['price'].replace({'\\\\$': '', ',': ''}, regex=True)\n",
    "    df['price'] = pd.to_numeric(df['price'], downcast='integer')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_url_list(driver):\n",
    "    \"\"\"Returns list of html containing url sub-directories.\"\"\"\n",
    "    soup = make_soup(driver)\n",
    "\n",
    "    # find html with diamond url page and return it\n",
    "    return soup.find('a', {'class': 'td-n2'})\n",
    "\n",
    "\n",
    "def create_url_df(driver):\n",
    "    \"\"\"Returns DataFrame with diamond id and individual diamond urls.\"\"\"\n",
    "\n",
    "    url_list = get_url_list(driver)\n",
    "    url_dict = {}\n",
    "    base = 'https://www.brilliantearth.com/'\n",
    "\n",
    "    # extract url sub-directory & id and add to dict\n",
    "    for ix, i in enumerate(url_list[:-1], start=1):\n",
    "        href = i.attrs.get('href')\n",
    "        d_id = re.findall(\"([0-9]+)\", href)[0]\n",
    "\n",
    "        # add diamond id and url to dict\n",
    "        url_dict[ix] = {'id': d_id, 'url': base + href}\n",
    "\n",
    "    # construct pandas DataFrame from url_dict and return it\n",
    "    return pd.DataFrame.from_dict(url_dict, orient='index')\n",
    "\n",
    "\n",
    "def merge_dfs(left_df, right_df):\n",
    "    \"\"\"Merges 'df' and 'url_df' and returns merged DataFrame.\"\"\"\n",
    "    return pd.merge(left_df, right_df, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "def set_price(driver, max_price: str):\n",
    "    \"\"\"Filters diamonds results based on price range.\"\"\"\n",
    "    perform_actions(driver, 'min_price_display', max_price)\n",
    "    sleep(3)\n",
    "\n",
    "\n",
    "def final_cleaning(df, diamond_type):\n",
    "    \"\"\"Returns DataFrame - removes duplicates, adds 'type' & 'date_fetched' columns.\"\"\"\n",
    "    clean_df = df.copy()\n",
    "    clean_df = clean_df.drop_duplicates()\n",
    "    clean_df['type'] = diamond_type\n",
    "    clean_df['date_fetched'] = timestamp\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def to_csv(df):\n",
    "    \"\"\"Writes a CSV file in the 'data' directory.\"\"\"\n",
    "    # remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "\n",
    "def get_max_price(df):\n",
    "    \"\"\"Returns string of the max 'price' in the DataFrame.\"\"\"\n",
    "    return str(df['price'].max())\n",
    "\n",
    "\n",
    "def get_last_id(df):\n",
    "    \"\"\"Returns the 'id' of the last row in the DataFrame.\"\"\"\n",
    "    return df['id'].iloc[-1]\n",
    "\n",
    "\n",
    "def test_price(driver):\n",
    "    perform_actions(driver, 'min_price_display', '15000')\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run script.\"\"\"\n",
    "    print('Attempting to scrape diamonds data. This could take a while...')\n",
    "    tic = perf_counter()\n",
    "    final_df = pd.DataFrame()\n",
    "    diamond_types = ['natural', 'lab']\n",
    "    for ix, dt in enumerate(diamond_types):\n",
    "        dr = create_webdriver()\n",
    "        try:\n",
    "            # first scrape attempt\n",
    "            load_url(dr, dt)\n",
    "            close_marketing_box(dr)\n",
    "            select_shapes(dr, ix)\n",
    "            test_price(dr)\n",
    "            set_max_carat(dr)\n",
    "            set_max_price(dr)\n",
    "            table_scroll(dr)\n",
    "\n",
    "            # create and clean DataFrame to append to\n",
    "            raw_df = create_dataframe(dr)\n",
    "            table_df = clean_table_df(raw_df)\n",
    "            url_df = create_url_df(dr)\n",
    "            df1 = merge_dfs(url_df, table_df)\n",
    "\n",
    "            # get max price & id from the DataFrame to filter diamonds for next scrape\n",
    "            prev_max_price = get_max_price(df1)\n",
    "            prev_last_id = get_last_id(df1)\n",
    "\n",
    "            # scrape remaining rows by iterating the price range\n",
    "            while True:\n",
    "                # scrape diamonds table\n",
    "                set_price(dr, prev_max_price)\n",
    "                table_scroll(dr)\n",
    "\n",
    "                # create and clean DataFrame, and append to 'df1' (created in first pass)\n",
    "                raw_df = create_dataframe(dr)\n",
    "                table_df = clean_table_df(raw_df)\n",
    "                url_df = create_url_df(dr)\n",
    "                merged_df = merge_dfs(url_df, table_df)\n",
    "                df1 = df1.append(merged_df)\n",
    "\n",
    "                # set current max price & id using the last row scraped\n",
    "                current_max_price = get_max_price(df1)\n",
    "                current_last_id = get_last_id(df1)\n",
    "\n",
    "                # check if price and id of the last row have been scraped\n",
    "                if current_max_price != prev_max_price and \\\n",
    "                        current_last_id != prev_last_id:\n",
    "                    prev_max_price = current_max_price\n",
    "                    prev_last_id = current_last_id\n",
    "\n",
    "                # else there are no new diamond results, export DataFrame\n",
    "                else:\n",
    "                    clean_df = final_cleaning(df1, dt)\n",
    "                    final_df = final_df.append(clean_df)\n",
    "                    break\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            take_screenshot()\n",
    "        finally:\n",
    "            dr.quit()\n",
    "    else:\n",
    "        to_csv(final_df)\n",
    "        print(f\"CSV path: {csv_path}\")\n",
    "        toc = perf_counter()\n",
    "        duration = (toc - tic) / 60\n",
    "        print(f\"Finished in {duration:0.1f} minutes\")\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2020-11-29 12-26 PM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119307 entries, 0 to 119306\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   id            119307 non-null  int64  \n",
      " 1   url           119307 non-null  object \n",
      " 2   shape         119307 non-null  object \n",
      " 3   price         119307 non-null  int64  \n",
      " 4   carat         119307 non-null  float64\n",
      " 5   cut           119307 non-null  object \n",
      " 6   color         119307 non-null  object \n",
      " 7   clarity       119307 non-null  object \n",
      " 8   report        119307 non-null  object \n",
      " 9   type          119307 non-null  object \n",
      " 10  date_fetched  119307 non-null  object \n",
      "dtypes: float64(1), int64(2), object(8)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>shape</th>\n",
       "      <th>price</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>report</th>\n",
       "      <th>type</th>\n",
       "      <th>date_fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10086429</td>\n",
       "      <td>https://www.brilliantearth.com//loose-diamonds...</td>\n",
       "      <td>Round</td>\n",
       "      <td>400</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>GIA</td>\n",
       "      <td>natural</td>\n",
       "      <td>2020-11-29 12-26 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10016334</td>\n",
       "      <td>https://www.brilliantearth.com//loose-diamonds...</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>400</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>GIA</td>\n",
       "      <td>natural</td>\n",
       "      <td>2020-11-29 12-26 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9947216</td>\n",
       "      <td>https://www.brilliantearth.com//loose-diamonds...</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>400</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>GIA</td>\n",
       "      <td>natural</td>\n",
       "      <td>2020-11-29 12-26 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10083437</td>\n",
       "      <td>https://www.brilliantearth.com//loose-diamonds...</td>\n",
       "      <td>Round</td>\n",
       "      <td>400</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>SI2</td>\n",
       "      <td>GIA</td>\n",
       "      <td>natural</td>\n",
       "      <td>2020-11-29 12-26 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9946136</td>\n",
       "      <td>https://www.brilliantearth.com//loose-diamonds...</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>400</td>\n",
       "      <td>0.30</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>GIA</td>\n",
       "      <td>natural</td>\n",
       "      <td>2020-11-29 12-26 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                url    shape  \\\n",
       "0  10086429  https://www.brilliantearth.com//loose-diamonds...    Round   \n",
       "1  10016334  https://www.brilliantearth.com//loose-diamonds...  Emerald   \n",
       "2   9947216  https://www.brilliantearth.com//loose-diamonds...  Emerald   \n",
       "3  10083437  https://www.brilliantearth.com//loose-diamonds...    Round   \n",
       "4   9946136  https://www.brilliantearth.com//loose-diamonds...  Emerald   \n",
       "\n",
       "   price  carat        cut color clarity report     type         date_fetched  \n",
       "0    400   0.30  Very Good     J     SI2    GIA  natural  2020-11-29 12-26 PM  \n",
       "1    400   0.31      Ideal     I     SI1    GIA  natural  2020-11-29 12-26 PM  \n",
       "2    400   0.30      Ideal     I     VS2    GIA  natural  2020-11-29 12-26 PM  \n",
       "3    400   0.30      Ideal     I     SI2    GIA  natural  2020-11-29 12-26 PM  \n",
       "4    400   0.30      Ideal     I     SI1    GIA  natural  2020-11-29 12-26 PM  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
